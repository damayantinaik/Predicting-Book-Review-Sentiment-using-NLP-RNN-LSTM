{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c7d90f",
   "metadata": {},
   "source": [
    "# Predicting Book Review Sentiment Using NLP-RNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a25042",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed627e90",
   "metadata": {},
   "source": [
    "This project is based on Deep Learning and Natural Language Processing. To make the prediction\n",
    "of book-review's sentiment, I've used RNN-LSTM ('Recurrent Neural Network'-'Long Short-Term Memory') method.\n",
    "\n",
    "RNN works with sequential data i.e when the data at a certain time depends on the data in the previous time steps. For example: words in order in a sentence, data of daily stock price, historical unemployment figure etc.\n",
    "\n",
    "In RNN, the outputs from the hidden layers loops back and goes into hidden layer again. The reason, RNN needs to have the output of the hidden layer loops back because the prediction or ultimate output from the network is based on the current and historic data.\n",
    "\n",
    "In a LSTM, it has the ability to remember longer sequences of data than an ordinary RNN. It categorizes data into short-term and long-term memory. By doing this, it remembers the important data, loops back those in the network for prediction and forgets the other. This enables LSTM to use long sequence of data to make prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e2bf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4051e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd7c76b",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee95cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Amazon_review.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc673cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿date</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>It was ok. Few good parts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/20/2020</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I was bored to tears. I could not read anymore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The book was bad. I was really bored.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/4/2020</td>\n",
       "      <td>Julio</td>\n",
       "      <td>Negative</td>\n",
       "      <td>One of the worst book I ever read.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>Kareem</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Nothing really exciting.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ï»¿date    name sentiment  \\\n",
       "0   10/1/2020     Bob   Neutral   \n",
       "1  10/20/2020    Jeff  Negative   \n",
       "2   12/3/2020    Mary  Negative   \n",
       "3   12/4/2020   Julio  Negative   \n",
       "4   12/5/2020  Kareem   Neutral   \n",
       "\n",
       "                                              text  \n",
       "0                       It was ok. Few good parts.  \n",
       "1  I was bored to tears. I could not read anymore.  \n",
       "2            The book was bad. I was really bored.  \n",
       "3               One of the worst book I ever read.  \n",
       "4                         Nothing really exciting.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf17ff",
   "metadata": {},
   "source": [
    "## Data wrangling & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b776c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'ï»¿date': 'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc29d29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>It was ok. Few good parts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/20/2020</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I was bored to tears. I could not read anymore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The book was bad. I was really bored.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/4/2020</td>\n",
       "      <td>Julio</td>\n",
       "      <td>Negative</td>\n",
       "      <td>One of the worst book I ever read.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>Kareem</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Nothing really exciting.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    name sentiment  \\\n",
       "0   10/1/2020     Bob   Neutral   \n",
       "1  10/20/2020    Jeff  Negative   \n",
       "2   12/3/2020    Mary  Negative   \n",
       "3   12/4/2020   Julio  Negative   \n",
       "4   12/5/2020  Kareem   Neutral   \n",
       "\n",
       "                                              text  \n",
       "0                       It was ok. Few good parts.  \n",
       "1  I was bored to tears. I could not read anymore.  \n",
       "2            The book was bad. I was really bored.  \n",
       "3               One of the worst book I ever read.  \n",
       "4                         Nothing really exciting.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd7ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582daf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 'Neutral' data, as my goal is to detect positive/negative reviews.\n",
    "data = data[data.sentiment != 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9582faa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I was bored to tears. I could not read anymore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>The book was bad. I was really bored.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>One of the worst book I ever read.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I loved it !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td># I hated it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             text\n",
       "1  Negative  I was bored to tears. I could not read anymore.\n",
       "2  Negative            The book was bad. I was really bored.\n",
       "3  Negative               One of the worst book I ever read.\n",
       "5  Positive                                     I loved it !\n",
       "6  Negative                                    # I hated it."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2e2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters from text column and convert them to lowercase\n",
    "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', ' ', x))\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06527f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>i was bored to tears  i could not read anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the book was bad  i was really bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>one of the worst book i ever read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i loved it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>i hated it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative</td>\n",
       "      <td>really bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>a really dissapintment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>it bored me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i liked it a lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i enjoyed it  i loved it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Positive</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Negative</td>\n",
       "      <td>boring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i loved it so much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Negative</td>\n",
       "      <td>the absolute worst book i ever read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive</td>\n",
       "      <td>a real thrill  loved it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Negative</td>\n",
       "      <td>a waste of money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Positive</td>\n",
       "      <td>please write more books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Positive</td>\n",
       "      <td>one of the best books i ve read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             text\n",
       "1   Negative  i was bored to tears  i could not read anymore \n",
       "2   Negative            the book was bad  i was really bored \n",
       "3   Negative               one of the worst book i ever read \n",
       "5   Positive                                     i loved it  \n",
       "6   Negative                                      i hated it \n",
       "7   Negative                                      really bad \n",
       "8   Negative                          a really dissapintment \n",
       "9   Negative                                     it bored me \n",
       "10  Positive                                i liked it a lot \n",
       "11  Negative                                       the worst \n",
       "12  Positive                       i enjoyed it  i loved it  \n",
       "13  Positive                                      excellent  \n",
       "14  Negative                                          boring \n",
       "15  Positive                             i loved it so much  \n",
       "16  Negative             the absolute worst book i ever read \n",
       "17  Positive                         a real thrill  loved it \n",
       "18  Negative                                a waste of money \n",
       "19  Positive                        please write more books  \n",
       "20  Positive                 one of the best books i ve read "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0c589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000 # This is the maximum number of vocabulary I am going to use in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e86a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words, split = ' ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1e3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word is assigned a number, higher the frequency of the word in the entire text,\n",
    "# lower the number and vice-versa. \n",
    "tokenizer.fit_on_texts(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e721c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index puts all words and corresponding index in a dictionary\n",
    "words = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6ffa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'it': 2, 'the': 3, 'read': 4, 'loved': 5, 'a': 6, 'was': 7, 'bored': 8, 'book': 9, 'really': 10, 'of': 11, 'worst': 12, 'bad': 13, 'one': 14, 'ever': 15, 'books': 16, 'to': 17, 'tears': 18, 'could': 19, 'not': 20, 'anymore': 21, 'hated': 22, 'dissapintment': 23, 'me': 24, 'liked': 25, 'lot': 26, 'enjoyed': 27, 'excellent': 28, 'boring': 29, 'so': 30, 'much': 31, 'absolute': 32, 'real': 33, 'thrill': 34, 'waste': 35, 'money': 36, 'please': 37, 'write': 38, 'more': 39, 'best': 40, 've': 41}\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc5ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = max([i for i in words.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2421a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f42574",
   "metadata": {},
   "source": [
    "Below, I'll take each text entry and replace all the words in it with their corresponding integer values from the word_index dictionary. In other words, each review represents as a series of numbers and enter it into an array called X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d8a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e61dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 7, 8, 17, 18, 1, 19, 20, 4, 21], [3, 9, 7, 13, 1, 7, 10, 8], [14, 11, 3, 12, 9, 1, 15, 4], [1, 5, 2], [1, 22, 2], [10, 13], [6, 10, 23], [2, 8, 24], [1, 25, 2, 6, 26], [3, 12], [1, 27, 2, 1, 5, 2], [28], [29], [1, 5, 2, 30, 31], [3, 32, 12, 9, 1, 15, 4], [6, 33, 34, 5, 2], [6, 35, 11, 36], [37, 38, 39, 16], [14, 11, 3, 40, 16, 1, 41, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9dd08",
   "metadata": {},
   "source": [
    "In the following cell, I padded each array putting zeros to make each sentiment equal (padding started from the begining by default unless I specify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2b8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd39672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7  8 17 18  1 19 20  4 21]\n",
      " [ 0  0  3  9  7 13  1  7 10  8]\n",
      " [ 0  0 14 11  3 12  9  1 15  4]\n",
      " [ 0  0  0  0  0  0  0  1  5  2]\n",
      " [ 0  0  0  0  0  0  0  1 22  2]\n",
      " [ 0  0  0  0  0  0  0  0 10 13]\n",
      " [ 0  0  0  0  0  0  0  6 10 23]\n",
      " [ 0  0  0  0  0  0  0  2  8 24]\n",
      " [ 0  0  0  0  0  1 25  2  6 26]\n",
      " [ 0  0  0  0  0  0  0  0  3 12]\n",
      " [ 0  0  0  0  1 27  2  1  5  2]\n",
      " [ 0  0  0  0  0  0  0  0  0 28]\n",
      " [ 0  0  0  0  0  0  0  0  0 29]\n",
      " [ 0  0  0  0  0  1  5  2 30 31]\n",
      " [ 0  0  0  3 32 12  9  1 15  4]\n",
      " [ 0  0  0  0  0  6 33 34  5  2]\n",
      " [ 0  0  0  0  0  0  6 35 11 36]\n",
      " [ 0  0  0  0  0  0 37 38 39 16]\n",
      " [ 0  0 14 11  3 40 16  1 41  4]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d5fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32b30ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933be47",
   "metadata": {},
   "source": [
    "# NLP-RNN-LSTM Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f5ff56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # This creates an Instance of the Sequential model\n",
    "model.add(Embedding(input_dim = max_words, output_dim = 20, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(200, dropout = 0.1))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f757e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79004353",
   "metadata": {},
   "source": [
    "Note-1: categorical_crossentropy is a loss function used for what is known as multi_class classification. The loss function tells us how wrong your model's prediction are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185195e",
   "metadata": {},
   "source": [
    "Note-2: Adam is an optimization algorithm that is used to update the weights/parameters based on the data we input into the model in the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4a2f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 20)            200000    \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 10, 20)            0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200)               176800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 402       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377202 (1.44 MB)\n",
      "Trainable params: 377202 (1.44 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c95190e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment column to dummies numerical values \n",
    "Y = pd.get_dummies(data['sentiment']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cf405",
   "metadata": {},
   "source": [
    "## Train-test split, fit model & model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a27c1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a89c9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 10)\n",
      "(5, 10)\n",
      "(14, 2)\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eda5090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 - 3s - loss: 0.6952 - accuracy: 0.5000 - 3s/epoch - 909ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6812 - accuracy: 0.5714 - 54ms/epoch - 18ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6810 - accuracy: 0.5714 - 39ms/epoch - 13ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6762 - accuracy: 0.5714 - 51ms/epoch - 17ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.6715 - accuracy: 0.5714 - 54ms/epoch - 18ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.6585 - accuracy: 0.5714 - 58ms/epoch - 19ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.6390 - accuracy: 0.5714 - 43ms/epoch - 14ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.6374 - accuracy: 0.5714 - 38ms/epoch - 13ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.6473 - accuracy: 0.5714 - 51ms/epoch - 17ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.5929 - accuracy: 0.5714 - 41ms/epoch - 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19c3530ee10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9839500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 551ms/step - loss: 0.7480 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8800eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7480345964431763\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\", score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e82cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e97e21",
   "metadata": {},
   "source": [
    "## Testing model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1571507",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = ['It bored me.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e3ff61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = tokenizer.texts_to_sequences(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad11f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pad_sequences(review, maxlen = 10, dtype = 'int32', value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33e11da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - 446ms/epoch - 446ms/step\n"
     ]
    }
   ],
   "source": [
    "sentiment = model.predict(review, batch_size = 1, verbose = 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a13cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68032926 0.31967077]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db42b0",
   "metadata": {},
   "source": [
    "Note: Here, the first element of the output is the measurement of the probability of review being -ve,whereas the second element is the probability that measures the review of being +ve. \n",
    "\n",
    "So the model is predicting that the review has 68% chance of being -ve review, and 31% chance of being +ve review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1758a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.argmax(sentiment) == 0): # argmax reprents the index of the highest number in the array 'sentiment' \n",
    "    print(\"This is a negative review.\")\n",
    "\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"This is a positive review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975840f9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1d9ad",
   "metadata": {},
   "source": [
    "In this project, I built a NLP-RNN-LSTM model to identfy the sentimental/emotional tone of a Book review. Preprocessing on the data was done carefully. First, I tokenized each text into a bunch of words, assigned each one an index number based on its frequency of occurence in the entire text set. I kept my maximum word length to 10,000 to have maximum capacity of the model to handle large set of vocabulary. I padded each text with 0 making them of equal size. In the LSTM model, I included 20% 1D Spatial Dropout to prevent overfitting. The model was complied with 'categorical cross-entropy' as loss, adam optimizer and accuracy as evaluation metrics. The Model was trained on labeled data, and then tested on an unseen review, on which it could predict the correct sentiment with 68% probablity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
